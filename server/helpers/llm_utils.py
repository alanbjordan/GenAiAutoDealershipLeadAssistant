# helpers/llm_utils.py
import os
from openai import OpenAI

client = OpenAI(
    api_key = os.getenv("OPENAI_API_KEY"),
)

if not client.api_key:
    raise ValueError("API key not found. Please set the OPENAI_API_KEY environment variable.")


def generate_llm_natural_output(message_content: str) -> str:
    """
    Uses OpenAI's API to assist a user in their car search and test drive scheduling.

    The assistant's responsibilities include:
    1. Extracting relevant user preferences from their input.
    2. Querying the PostgreSQL database using provided tools to find matching cars.
    3. Summarizing suitable car options based on user preferences.
    4. Requesting user's contact information (primarily email).
    5. Encouraging users to schedule a test drive.

    Args:
        message_content (str): The user's input detailing their car preferences and needs.

    Returns:
        str: A refined and structured natural language response generated by the LLM.
    """

    prompt = (
        """
        "IMPORTANT RETURN YOUR RESPONSE IN MARKDOWN FORMAT\n"
        "You are a friendly and professional car dealership assistant helping a user find their perfect car.

        Steps to follow internally:
        1. Extract user preferences from the input.
        2. Query PostgreSQL database using provided tools.
        3. Identify a suitable vehicle.

        DO NOT explain these steps or your internal logic to the user.

        Respond conversationally and naturally, gently guiding the user toward providing their contact information and scheduling a test drive, without making your intentions explicitly obvious. Your response should feel engaging and helpful, NOT robotic or overly direct.
        """

        "User-provided information:\n"
        f"{message_content}\n\n"

        "Generate your response clearly structured into:\n"
        "- Clarification questions (if any)\n"
        "- Summary of suitable vehicle options\n"
        "- Request for user's contact information (email)\n"
        "- Direct call-to-action for scheduling a test drive\n"

    )

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": message_content}
        ]
    )
    response_text = response.choices[0].message.content
    print(f"LLM Response: {response_text}")
    
    return response_text
